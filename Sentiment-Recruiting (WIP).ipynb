{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import exp, array, random, dot\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import en_core_web_sm\n",
    "import vaderSentiment\n",
    "from gensim.models import KeyedVectors\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from IPython import display\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import fastText\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identification of sentiment in text is an important field of study, it usually involves detecting whether a piece of text expresses a POSITIVE, a NEGATIVE, or a NEUTRAL sentiment; the sentiment can be general or about a specific topic, e.g., a person, a product, or an event.\n",
    "\n",
    "Sentiment analysis has been part of the international workshop on Semantic Evaluation ([SemEval](https://en.wikipedia.org/wiki/SemEval)) for multiple years ([2016](http://anthology.aclweb.org/S/S16/S16-1001.pdf), [2017](http://www.aclweb.org/anthology/S17-2088)).\n",
    "\n",
    "You task is to implement a neural network that predicts sentiment (POSITIVE, NEGATIVE, NEUTRAL) for a given text.\n",
    "\n",
    "In the following sections, we provide the dataset preperation, a basic model, training and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are using to train and test our model is generated from German Amazon reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is the text of the review, and the network will try to predict the star ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include only reviews with 1,3 and 5 star ratings, where: \n",
    "* 1 is considered negative\n",
    "* 3 is considered neutral\n",
    "* 5 is considered positive\n",
    "\n",
    "All reviews with rating 2,4 are not included in our dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already created a python script that returns amazon reviews whose star ratings are either 1,3 or 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DON'T NEED TO RUN EVERYTIME\n",
    "dfTest =pd.read_csv(\"tweetTrainingContext.csv\", header=None)\n",
    "dfTest.drop(0, axis=1, inplace=True)\n",
    "dfTest = dfTest[dfTest[2] != 1]\n",
    "dfTest = dfTest[dfTest[2] != -1]\n",
    "dfTest.loc[dfTest[2] == 2, 2] = 5\n",
    "dfTest.loc[dfTest[2] == -2, 2] = 1\n",
    "dfTest.loc[dfTest[2] == 0, 2] = 3\n",
    "#dfTest[2].sample(n=43, replace=True, random_state=1)\n",
    "print (Counter(dfTest[2]))\n",
    "dfTest.columns=['subject','label','body']\n",
    "dfTest.to_csv(\"tweetTrainingContextFilter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD TRAINING DATA\n",
    "#{3: 2912, 5: 638, 1: 161})\n",
    "dfTrain = pd.read_csv(\"tweetTrainingContextFilter.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@PersonaSoda well yeah, that's third parties. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Sony's 1st teaser package for the launch of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>#tv Ind vs SL 3rd Test Day 3: Cricket live sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@TruthInsider @bertymufc @gamerxone720 @PNF4LY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@greencapt Official reason, because the game h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>I know it's coming coon but I don't get why it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>At least Sony will probably be selling it for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@InnoBystander Might keep SONY monthly subs go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Uncharted 4: A Thief's End launches for PS4 in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@Adam_OliverYT Hi Adam, you may need to contac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Oh my gosh actual acknowledgement from Sony th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Sony may release first smartphone with 4K scre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@vsamuel323 For any information on this we ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Rich Guys Can't Make Other Rich Guys Look Bad:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>sony</td>\n",
       "      <td>1</td>\n",
       "      <td>Exactly why I'll never buy Sony. Those 1st cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Sony may have cut scenes from #WillSmith's fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>39</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>New phone on Saturday! Torn between Sony z3 or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Do you see Sony pulling shit like this? No.  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Sony went all out with this new high-tech smar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Sony's pulling a #TASM2 by beginning pre-produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@martymegs @SonyUK @johnlewisretail it's Frida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Sony Xperia Z5, Xperia Z5 Compact Price, Xperi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>47</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>Xperia Z5 pre-orders available at the Carphone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>48</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>#IFA2015: International Fair of Electronic Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>51</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@GeorgeGegham Marvel is in charge now, no way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>52</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>M$: Sony is gobbling up 3rd Party Exclusives  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>The New York Times reported Tuesday that Sony ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>54</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>What evidence is there that says North Korea h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>55</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@StevieBenton Dunno about tinder style. Sony h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>59</td>\n",
       "      <td>sony</td>\n",
       "      <td>3</td>\n",
       "      <td>@blakejharrisNYC could hit the 3rd console war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>9897</td>\n",
       "      <td>messi</td>\n",
       "      <td>5</td>\n",
       "      <td>Top 3 players in the world? Has to be: Suarez/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>9899</td>\n",
       "      <td>messi</td>\n",
       "      <td>3</td>\n",
       "      <td>May as well scribble out the 5 on the FIFA 15 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>9901</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>Sigh otra MetLife is tomorrow and I'm not goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>9905</td>\n",
       "      <td>metlife</td>\n",
       "      <td>5</td>\n",
       "      <td>@Harry_Styles goodnight babe hope you are rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>9906</td>\n",
       "      <td>metlife</td>\n",
       "      <td>5</td>\n",
       "      <td>@NiallOfficial hope you have a nice day tomorr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>9910</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>@itssabrinagable some acc on twitter which is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>9911</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>I wish I was going to MetLife tonight but I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>9912</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>@bestdittyvideos ok so someone on Twitter said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>9913</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>today is the day \"harry styles will die at met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>9923</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>@hsdelevingne he had death threats in july (I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>9929</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll upload the rest of my videos from MetLife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>9930</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>Panoramas of the crowd/stadium last night at M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3693</th>\n",
       "      <td>9931</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>@uanreckless @_Soma_MO Yeah I saw that. It loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>9933</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>I couldn't go to MetLife so I'm going to a con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>9936</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>@CLoprestiWFAN Did I just hear Bowles say that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>9937</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>I may haven't been close to Louis at MetLife b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>9939</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>Todd Bowles and players talk about what they'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>9946</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>did jessie almost faint at MetLife too the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>9948</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>Harry talking to the 9 year old boy/auctioning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>9949</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>@ItIsWhatItIs__ yea I went to the one at MetLi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>9973</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>It's the Atlanta Falcons (1-0) against the New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>9975</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll be live streaming the sad Giants fans via...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>9977</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>I have 4 seats to the Giants game at MetLife t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>9978</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>I have one possibly two extra tickets to see Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>9979</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>im going to metlife tomorrow for a preseason g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>9980</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>@RawbCas3 Alright, let me know. Want to see AC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>9981</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>Going to the Giants-Panthers game December 20 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>9996</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>9997</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>9998</td>\n",
       "      <td>metlife</td>\n",
       "      <td>3</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3711 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  subject  label  \\\n",
       "0              1     sony      3   \n",
       "1              6     sony      3   \n",
       "2              7     sony      3   \n",
       "3              8     sony      3   \n",
       "4              9     sony      3   \n",
       "5             12     sony      3   \n",
       "6             15     sony      3   \n",
       "7             16     sony      3   \n",
       "8             18     sony      3   \n",
       "9             21     sony      3   \n",
       "10            22     sony      3   \n",
       "11            31     sony      3   \n",
       "12            33     sony      3   \n",
       "13            34     sony      3   \n",
       "14            36     sony      1   \n",
       "15            37     sony      3   \n",
       "16            39     sony      3   \n",
       "17            40     sony      3   \n",
       "18            41     sony      3   \n",
       "19            43     sony      3   \n",
       "20            44     sony      3   \n",
       "21            45     sony      3   \n",
       "22            47     sony      3   \n",
       "23            48     sony      3   \n",
       "24            51     sony      3   \n",
       "25            52     sony      3   \n",
       "26            53     sony      3   \n",
       "27            54     sony      3   \n",
       "28            55     sony      3   \n",
       "29            59     sony      3   \n",
       "...          ...      ...    ...   \n",
       "3681        9897    messi      5   \n",
       "3682        9899    messi      3   \n",
       "3683        9901  metlife      3   \n",
       "3684        9905  metlife      5   \n",
       "3685        9906  metlife      5   \n",
       "3686        9910  metlife      3   \n",
       "3687        9911  metlife      3   \n",
       "3688        9912  metlife      3   \n",
       "3689        9913  metlife      3   \n",
       "3690        9923  metlife      3   \n",
       "3691        9929  metlife      3   \n",
       "3692        9930  metlife      3   \n",
       "3693        9931  metlife      3   \n",
       "3694        9933  metlife      3   \n",
       "3695        9936  metlife      3   \n",
       "3696        9937  metlife      3   \n",
       "3697        9939  metlife      3   \n",
       "3698        9946  metlife      3   \n",
       "3699        9948  metlife      3   \n",
       "3700        9949  metlife      3   \n",
       "3701        9973  metlife      3   \n",
       "3702        9975  metlife      3   \n",
       "3703        9977  metlife      3   \n",
       "3704        9978  metlife      3   \n",
       "3705        9979  metlife      3   \n",
       "3706        9980  metlife      3   \n",
       "3707        9981  metlife      3   \n",
       "3708        9996  metlife      3   \n",
       "3709        9997  metlife      3   \n",
       "3710        9998  metlife      3   \n",
       "\n",
       "                                                   body  \n",
       "0     @PersonaSoda well yeah, that's third parties. ...  \n",
       "1     Sony's 1st teaser package for the launch of th...  \n",
       "2     #tv Ind vs SL 3rd Test Day 3: Cricket live sco...  \n",
       "3     @TruthInsider @bertymufc @gamerxone720 @PNF4LY...  \n",
       "4     @greencapt Official reason, because the game h...  \n",
       "5     I know it's coming coon but I don't get why it...  \n",
       "6     At least Sony will probably be selling it for ...  \n",
       "7     @InnoBystander Might keep SONY monthly subs go...  \n",
       "8     Uncharted 4: A Thief's End launches for PS4 in...  \n",
       "9     @Adam_OliverYT Hi Adam, you may need to contac...  \n",
       "10    Oh my gosh actual acknowledgement from Sony th...  \n",
       "11    Sony may release first smartphone with 4K scre...  \n",
       "12    @vsamuel323 For any information on this we ask...  \n",
       "13    Rich Guys Can't Make Other Rich Guys Look Bad:...  \n",
       "14    Exactly why I'll never buy Sony. Those 1st cla...  \n",
       "15    Sony may have cut scenes from #WillSmith's fil...  \n",
       "16    New phone on Saturday! Torn between Sony z3 or...  \n",
       "17    Do you see Sony pulling shit like this? No.  h...  \n",
       "18    Sony went all out with this new high-tech smar...  \n",
       "19    Sony's pulling a #TASM2 by beginning pre-produ...  \n",
       "20    @martymegs @SonyUK @johnlewisretail it's Frida...  \n",
       "21    Sony Xperia Z5, Xperia Z5 Compact Price, Xperi...  \n",
       "22    Xperia Z5 pre-orders available at the Carphone...  \n",
       "23    #IFA2015: International Fair of Electronic Con...  \n",
       "24    @GeorgeGegham Marvel is in charge now, no way ...  \n",
       "25    M$: Sony is gobbling up 3rd Party Exclusives  ...  \n",
       "26    The New York Times reported Tuesday that Sony ...  \n",
       "27    What evidence is there that says North Korea h...  \n",
       "28    @StevieBenton Dunno about tinder style. Sony h...  \n",
       "29    @blakejharrisNYC could hit the 3rd console war...  \n",
       "...                                                 ...  \n",
       "3681  Top 3 players in the world? Has to be: Suarez/...  \n",
       "3682  May as well scribble out the 5 on the FIFA 15 ...  \n",
       "3683  Sigh otra MetLife is tomorrow and I'm not goin...  \n",
       "3684  @Harry_Styles goodnight babe hope you are rest...  \n",
       "3685  @NiallOfficial hope you have a nice day tomorr...  \n",
       "3686  @itssabrinagable some acc on twitter which is ...  \n",
       "3687  I wish I was going to MetLife tonight but I'm ...  \n",
       "3688  @bestdittyvideos ok so someone on Twitter said...  \n",
       "3689  today is the day \"harry styles will die at met...  \n",
       "3690  @hsdelevingne he had death threats in july (I ...  \n",
       "3691  I'll upload the rest of my videos from MetLife...  \n",
       "3692  Panoramas of the crowd/stadium last night at M...  \n",
       "3693  @uanreckless @_Soma_MO Yeah I saw that. It loo...  \n",
       "3694  I couldn't go to MetLife so I'm going to a con...  \n",
       "3695  @CLoprestiWFAN Did I just hear Bowles say that...  \n",
       "3696  I may haven't been close to Louis at MetLife b...  \n",
       "3697  Todd Bowles and players talk about what they'r...  \n",
       "3698  did jessie almost faint at MetLife too the wor...  \n",
       "3699  Harry talking to the 9 year old boy/auctioning...  \n",
       "3700  @ItIsWhatItIs__ yea I went to the one at MetLi...  \n",
       "3701  It's the Atlanta Falcons (1-0) against the New...  \n",
       "3702  I'll be live streaming the sad Giants fans via...  \n",
       "3703  I have 4 seats to the Giants game at MetLife t...  \n",
       "3704  I have one possibly two extra tickets to see Z...  \n",
       "3705  im going to metlife tomorrow for a preseason g...  \n",
       "3706  @RawbCas3 Alright, let me know. Want to see AC...  \n",
       "3707  Going to the Giants-Panthers game December 20 ...  \n",
       "3708  everyone who sat around me at metlife was so a...  \n",
       "3709  what giants or niners fans would wanna go to t...  \n",
       "3710  Anybody want a ticket for tomorrow Colombia vs...  \n",
       "\n",
       "[3711 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfTrain\n",
    "dfTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of reviews is originally not equally distributed among the ratings, so we downsampled the reviews so that there is the same number for each rating. The discarded reviews are picked at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 675, 5: 53, 1: 43})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out some data examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'free' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-52bf09be1615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfree\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'free' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert text to vector space, we use [word embeddings](https://en.wikipedia.org/wiki/Word_embedding) where words from the vocabulary are mapped to vectors of real numbers.\n",
    "\n",
    "Multiple versions of the word embeddings have already been implemented, we use Facebook's [FastText](https://research.fb.com/fasttext/) library.\n",
    "\n",
    "We trained our word embeddings on German wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS: Load Models\n",
    "twitterModel = KeyedVectors.load(\"twitterModel_1000000\")\n",
    "wikiModel = KeyedVectors.load(\"wikiModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Fasttext model (the following code might take some time to run, because the model is big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't have to run now\n",
    "#Creates model with word relationship given a vectors of tokenized sentances. Example: determines \"car\" is like \"automobile\"\n",
    "#basically creates model that understands human language based on input\n",
    "#takes maybe 15 min to run\n",
    "#vector i'm training on has a series of 300 token sentences/paragraphs\n",
    "en_model = KeyedVectors.load_word2vec_format(\"wiki-news-300d-1M.vec\")\n",
    "\n",
    "#en_model.save(\"wikiModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DON'T BOTHER RUNNING\n",
    "#Prove model is loaded\n",
    "words = []\n",
    "\n",
    "for word in wikiModel.vocab:\n",
    "\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 999994\n"
     ]
    }
   ],
   "source": [
    "#DON'T BOTHER RUNNING\n",
    "#number of words in vector\n",
    "print(\"Number of Tokens: {}\".format(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of a word vector: 300\n"
     ]
    }
   ],
   "source": [
    "#DON'T BOTHER RUNNING\n",
    "# Printing out the dimension of a word vector \n",
    "\n",
    "print(\"Dimension of a word vector: {}\".format(\n",
    "\n",
    "    len(wikiModel[words[0]])\n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector components of a word: [ 1.0730e-01  8.9000e-03  6.0000e-04  5.5000e-03 -6.4600e-02 -6.0000e-02\n",
      "  4.5000e-02 -1.3300e-02 -3.5700e-02  4.3000e-02 -3.5600e-02 -3.2000e-03\n",
      "  7.3000e-03 -1.0000e-04  2.5800e-02 -1.6600e-02  7.5000e-03  6.8600e-02\n",
      "  3.9200e-02  7.5300e-02  1.1500e-02 -8.7000e-03  4.2100e-02  2.6500e-02\n",
      " -6.0100e-02  2.4200e-01  1.9900e-02 -7.3900e-02 -3.1000e-03 -2.6300e-02\n",
      " -6.2000e-03  1.6800e-02 -3.5700e-02 -2.4900e-02  1.9000e-02 -1.8400e-02\n",
      " -5.3700e-02  1.4200e-01  6.0000e-02  2.2600e-02 -3.8000e-03 -6.7500e-02\n",
      " -3.6000e-03 -8.0000e-03  5.7000e-02  2.0800e-02  2.2300e-02 -2.5600e-02\n",
      " -1.5300e-02  2.2000e-03 -4.8200e-02  1.3100e-02 -6.0160e-01 -8.8000e-03\n",
      "  1.0600e-02  2.2900e-02  3.3600e-02  7.1000e-03  8.8700e-02  2.3700e-02\n",
      " -2.9000e-02 -4.0500e-02 -1.2500e-02  1.4700e-02  4.7500e-02  6.4700e-02\n",
      "  4.7400e-02  1.9900e-02  4.0800e-02  3.2200e-02  3.6000e-03  3.5000e-02\n",
      " -7.2300e-02 -3.0500e-02  1.8400e-02 -2.6000e-03  2.4000e-02 -1.6000e-02\n",
      " -3.0800e-02  4.3400e-02  1.4700e-02 -4.5700e-02 -2.6700e-02 -1.7030e-01\n",
      " -9.9000e-03  4.1700e-02  2.3500e-02 -2.6000e-02 -1.5190e-01 -1.1600e-02\n",
      " -3.0600e-02 -4.1300e-02  3.3000e-02  7.2300e-02  3.6500e-02 -1.0000e-04\n",
      "  4.2000e-03  3.4600e-02  2.7700e-02 -3.0500e-02  7.8400e-02 -4.0400e-02\n",
      "  1.8700e-02 -2.2500e-02 -2.0600e-02 -1.7900e-02 -2.4280e-01  6.6900e-02\n",
      "  5.2300e-02  5.2700e-02  1.4900e-02 -7.0800e-02 -9.8700e-02  2.6300e-02\n",
      " -6.1100e-02  3.0200e-02  2.1600e-02  3.1300e-02 -1.4000e-02 -2.4950e-01\n",
      " -3.4600e-02 -4.8000e-02  2.5000e-02  2.1300e-01 -3.3000e-02 -1.5530e-01\n",
      " -2.9200e-02 -3.4600e-02  1.0740e-01  1.0000e-03 -1.1700e-02 -5.7000e-03\n",
      " -1.2800e-01 -3.8000e-03  1.3000e-02 -1.1570e-01 -1.0800e-02  2.7500e-02\n",
      "  1.5800e-02 -1.6900e-02  7.0000e-03  2.4700e-02  5.1000e-02  1.0292e+00\n",
      " -2.8300e-02 -3.1000e-02 -2.6000e-03 -3.4300e-02  5.7800e-02  4.4400e-02\n",
      "  8.1200e-02 -2.1100e-02 -8.7200e-02  1.6900e-02  4.9900e-02  4.8500e-02\n",
      "  2.2700e-02 -3.2300e-02 -3.5000e-03  4.3500e-02 -2.7500e-02  1.5400e-02\n",
      "  1.3500e-02 -4.8400e-02 -6.9900e-02 -5.0200e-02  2.7450e-01 -3.0000e-04\n",
      " -3.7100e-02  5.1700e-02 -9.0800e-02  1.3000e-03  3.6000e-02  2.8000e-02\n",
      "  8.3900e-02  9.8000e-02 -4.9000e-02 -2.4230e-01 -1.4200e-02  2.4000e-03\n",
      " -2.0700e-02  1.2000e-03  8.8000e-03 -1.4300e-02 -1.9700e-02  5.1500e-02\n",
      " -8.5000e-03  2.5700e-02  2.1540e-01  3.0100e-02  2.1100e-02  5.3000e-02\n",
      " -5.0000e-04  1.7700e-02  1.6000e-03 -5.3000e-03 -1.6200e-02 -2.2300e-02\n",
      " -1.8620e-01  3.9800e-02  6.5800e-02 -9.6200e-02 -7.6000e-03 -7.5000e-03\n",
      " -3.4200e-02 -2.6500e-02  4.2000e-02  5.2200e-02 -2.6600e-02  2.0100e-02\n",
      " -1.3310e-01 -3.6700e-02  3.5100e-02  5.1800e-02 -8.7000e-03  5.9900e-02\n",
      " -1.0860e-01 -1.8800e-02  4.8100e-02  1.0500e-02 -6.0000e-03  1.5100e-02\n",
      " -3.1000e-03  7.7000e-03 -2.7600e-02 -3.7300e-02 -2.0300e-02  4.7200e-02\n",
      "  2.4600e-02  1.4400e-01  5.4200e-02 -2.2500e-02  2.4950e-01  1.6170e-01\n",
      "  3.8000e-03  1.1190e-01 -2.3000e-02 -7.8500e-02  2.5000e-02 -6.1600e-02\n",
      " -4.8500e-02  2.2500e-02  2.8100e-02  4.1000e-03  1.1200e-02  1.7200e-02\n",
      "  2.9100e-02 -2.8200e-02  2.6000e-03  4.0550e-01  3.9200e-02  8.8000e-03\n",
      "  2.2800e-02  2.9900e-02  1.1950e-01  5.4500e-02 -2.0000e-03  2.0000e-03\n",
      "  4.9000e-02  1.4500e-02 -8.6000e-03  9.8000e-03 -2.3600e-02  1.7100e-02\n",
      " -7.6500e-02 -4.0000e-02  1.2800e-02  1.1000e-03  4.2000e-03  2.4400e-02\n",
      "  7.5000e-03  2.0000e-02  2.0100e-02  1.9600e-02 -3.7700e-02 -4.3200e-02\n",
      " -7.3000e-03 -2.1000e-03  1.8300e-02  7.6000e-03  1.8050e-01 -5.5100e-02\n",
      "  7.5000e-03 -5.1600e-02  4.2000e-02 -6.8000e-03 -7.1100e-02 -1.4080e-01\n",
      "  5.0400e-02  2.7600e-02  4.7000e-02  3.2300e-02 -2.1900e-02  1.0000e-03\n",
      "  8.9000e-03  2.7600e-02  1.8600e-02  5.0000e-03  1.1730e-01 -4.0000e-02]\n"
     ]
    }
   ],
   "source": [
    "#DON'T BOTHER RUNNING\n",
    "# Print out the vector of a word \n",
    "\n",
    "print(\"Vector components of a word: {}\".format(\n",
    "\n",
    "    wikiModel[words[0]]\n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Hillary, Similarity: 0.78\n",
      "Word: Clintons, Similarity: 0.70\n",
      "Word: Cinton, Similarity: 0.69\n",
      "Word: Bush, Similarity: 0.69\n",
      "Word: Hiliary, Similarity: 0.69\n",
      "Word: Clinton-, Similarity: 0.68\n",
      "Word: CLinton, Similarity: 0.67\n",
      "Word: Obama, Similarity: 0.65\n",
      "Word: clinton, Similarity: 0.64\n",
      "Word: Clinto, Similarity: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jowo\\onedrive - microsoft\\john_woods\\projects\\ml capstone\\pytest\\env\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: clinton, Similarity: 0.46\n",
      "Word: HRC, Similarity: 0.41\n",
      "Word: She, Similarity: 0.39\n",
      "Word: Trump, Similarity: 0.38\n",
      "Word: she, Similarity: 0.38\n",
      "Word: HillaryClinton, Similarity: 0.37\n",
      "Word: her, Similarity: 0.36\n",
      "Word: Bernie, Similarity: 0.34\n",
      "Word: Tim, Similarity: 0.34\n",
      "Word: the, Similarity: 0.31\n"
     ]
    }
   ],
   "source": [
    "#DON'T BOTHER RUNNING\n",
    "# Finding out similar words [default= top 10]\n",
    "find_similar_to = 'Clinton'\n",
    "for similar_word in wikiModel.similar_by_word(find_similar_to):\n",
    "\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "\n",
    "        similar_word[0], similar_word[1]\n",
    "\n",
    "    ))\n",
    "for similar_word in twitterModel.similar_by_word(find_similar_to):\n",
    "\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "\n",
    "        similar_word[0], similar_word[1]\n",
    "\n",
    "    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What other word embedding models can we use and what are the advantages of using Fasttext?\n",
    "\n",
    "Please write your answer in the next cell:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Word2Vec, GloVe\n",
    "\n",
    "Fasttext is better as it divides the word in smaller parts (called n-grams), and then generate the model as per those n-grams.\n",
    "This help in cases of those words which are rarely used, OR are not present in training set. As the probabilty of n-grams \n",
    "repeating in vocab increases as compared to that rare word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert all text in the dataset into sequences of word indices. A \"word index\" would simply be an integer ID for the word. We will truncate the sequences to a maximum length of 200 words.\n",
    "If sequences are shorter than 100, then we need to pad them with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "#EMBEDDING_DIM = wikiModel.dim\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18959 unique tokens in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['PADDING']\n",
    "sequences = []\n",
    "for text in dfTrain.body:\n",
    "    text = text.split()\n",
    "    text_sequence = []\n",
    "    for word in text:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = len(inverse_vocabulary)\n",
    "            text_sequence.append(len(inverse_vocabulary))\n",
    "            inverse_vocabulary.append(word)\n",
    "        else:\n",
    "            text_sequence.append(vocabulary[word])\n",
    "    sequences.append(text_sequence)\n",
    "print(\"%d unique tokens in the vocabulary\" %len(vocabulary))\n",
    "\n",
    "bodies_seq = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    @PersonaSoda well yeah, that's third parties. ...\n",
      "1    Sony's 1st teaser package for the launch of th...\n",
      "Name: body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.body[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"\\n\", \"\",  text)\n",
    "    text = re.sub(r\"[-()]\", \"\", text)\n",
    "    text = re.sub(r\"\\.\", \" .\", text)\n",
    "    text = re.sub(r\"\\!\", \" !\", text)\n",
    "    text = re.sub(r\"\\?\", \" ?\", text)\n",
    "    text = re.sub(r\"\\,\", \" ,\", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"ohh\", \"oh\", text)\n",
    "    text = re.sub(r\"ohhh\", \"oh\", text)\n",
    "    text = re.sub(r\"ohhhh\", \"oh\", text)\n",
    "    text = re.sub(r\"ohhhhh\", \"oh\", text)\n",
    "    text = re.sub(r\"ohhhhhh\", \"oh\", text)\n",
    "    text = re.sub(r\"ahh\", \"ah\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies2 = []\n",
    "for line in dfTrain.body:\n",
    "    bodies2.append(clean_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies=bodies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13792 unique tokens in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['PADDING']\n",
    "sequences = []\n",
    "for text in bodies:\n",
    "    text = text.split()\n",
    "    text_sequence = []\n",
    "    for word in text:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = len(inverse_vocabulary)\n",
    "            text_sequence.append(len(inverse_vocabulary))\n",
    "            inverse_vocabulary.append(word)\n",
    "        else:\n",
    "            text_sequence.append(vocabulary[word])\n",
    "    sequences.append(text_sequence)\n",
    "print(\"%d unique tokens in the vocabulary\" %len(vocabulary))\n",
    "\n",
    "bodies_seq = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  3\n",
      "   4  5  6  7  8  9 10 11  6 12 13 14 15 16 17 18  9 18  6 19 20 21 22 23\n",
      "  24 25 26  9]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0 27 28 29 30 17 31 32 22 31 33 34 35 36 37 38 39\n",
      "  40 41 42 43]]\n"
     ]
    }
   ],
   "source": [
    "#INdex of words padded to 200 words\n",
    "print(bodies_seq[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "As you can see, there is a huge number of unique tokens extracted from the reviews. Can you think of any preprocessing steps to make the vocabulary smaller?\n",
    "\n",
    "Edit the code block above to add more preprocessing steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Train/Val/Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into 3 sets: train, validation and test.\n",
    "\n",
    "We use ```sklearn.model_selection.train_test_split``` twice. First to split to train, val and then split val again into val and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3339 examples\n",
      "Val: 334 examples\n",
      "Test: 38 examples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = {\n",
    "    'train': {},\n",
    "    'val': {},\n",
    "    'test': {},\n",
    "}\n",
    "\n",
    "(data['train']['text'],\n",
    " data['val']['text'],\n",
    " data['train']['y'],\n",
    " data['val']['y']\n",
    ") = train_test_split(bodies_seq, dfTrain.label, test_size=0.1)\n",
    "\n",
    "(data['val']['text'],\n",
    " data['test']['text'],\n",
    " data['val']['y'],\n",
    " data['test']['y']\n",
    ") = train_test_split(data['val']['text'], data['val']['y'], test_size=0.1)\n",
    "\n",
    "print('Train: {} examples'.format(len(data['train']['y'])))\n",
    "print('Val: {} examples'.format(len(data['val']['y'])))\n",
    "print('Test: {} examples'.format(len(data['test']['y'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2599    3\n",
       "2997    3\n",
       "871     1\n",
       "369     1\n",
       "705     3\n",
       "2460    3\n",
       "970     3\n",
       "1293    3\n",
       "2384    3\n",
       "3390    1\n",
       "446     3\n",
       "1754    3\n",
       "538     3\n",
       "1620    5\n",
       "3344    5\n",
       "3430    3\n",
       "377     1\n",
       "572     3\n",
       "2684    3\n",
       "3267    3\n",
       "797     3\n",
       "1852    3\n",
       "316     3\n",
       "3379    3\n",
       "2855    5\n",
       "1660    1\n",
       "2475    3\n",
       "786     3\n",
       "855     3\n",
       "3089    5\n",
       "       ..\n",
       "2703    3\n",
       "282     3\n",
       "3368    3\n",
       "617     3\n",
       "1860    3\n",
       "1523    3\n",
       "2600    3\n",
       "3141    3\n",
       "1640    1\n",
       "277     3\n",
       "5       3\n",
       "3504    3\n",
       "2707    5\n",
       "1518    3\n",
       "3260    3\n",
       "3676    3\n",
       "1266    3\n",
       "1063    3\n",
       "452     3\n",
       "702     3\n",
       "1115    3\n",
       "2136    5\n",
       "2764    3\n",
       "891     3\n",
       "1211    3\n",
       "1580    5\n",
       "3084    5\n",
       "1739    3\n",
       "3139    3\n",
       "2168    3\n",
       "Name: label, Length: 334, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['val']['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare an \"embedding matrix\" which will contain at index i the embedding vector for the word of index i in our word index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(vocabulary) + 1, EMBEDDING_DIM)) \n",
    "for word, i in vocabulary.items():\n",
    "    if word in wikiModel:\n",
    "        embedding_matrix[i] = wikiModel[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "How should we handle a word that is not found in the embeddings model (out of vocabulary words)?\n",
    "\n",
    "Please write your answer in the next cell:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In ideal scenario, we can either -\n",
    "a. Either ignore those words\n",
    "b. Or generate a random embedding\n",
    "\n",
    "However, as we are using Fasttext. Which divides word into smaller parts(n-grams). So, even though word does not exist in vocabulary, it will be able to generate the embeddings by matching those n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(MAX_SEQUENCE_LENGTH)\n",
    "print(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(keras.models.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        input_layer = layers.Input(\n",
    "            shape=(MAX_SEQUENCE_LENGTH,),\n",
    "            name='Input'\n",
    "        )\n",
    "        embedding_layer = layers.Embedding(len(vocabulary) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            name='Embedding',\n",
    "                            trainable=False)(input_layer)\n",
    "            \n",
    "        fc_layer = layers.Dense(\n",
    "            units=100,\n",
    "            name='FullyConnected'\n",
    "        )(embedding_layer)\n",
    "        \n",
    "        fc_layer  = layers.Flatten(name=\"Flatten\")(fc_layer)\n",
    "        \n",
    "        predictions = layers.Dense(\n",
    "            6,\n",
    "            name='Output'\n",
    "        )(fc_layer)\n",
    "        \n",
    "        super().__init__(inputs=[input_layer], outputs=predictions)\n",
    "        \n",
    "    def compile(self):\n",
    "        return super().compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "            loss='mse'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel()\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\jowo\\onedrive - microsoft\\john_woods\\projects\\ml capstone\\pytest\\env\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\jowo\\onedrive - microsoft\\john_woods\\projects\\ml capstone\\pytest\\env\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    996\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    998\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\jowo\\onedrive - microsoft\\john_woods\\projects\\ml capstone\\pytest\\env\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jowo\\onedrive - microsoft\\john_woods\\projects\\ml capstone\\pytest\\env\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c4fa2ccb2b7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jowo\\onedrive - microsoft\\john_woods\\projects\\ml capstone\\pytest\\env\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jowo\\onedrive - microsoft\\john_woods\\projects\\ml capstone\\pytest\\env\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         raise OSError(\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[1;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "#JUST FOR VISUALIZING MODEL? DON'T NEED?\n",
    "from graphviz import Digraph\n",
    "\n",
    "display.display(display.Image(keras.utils.vis_utils.model_to_dot(model, show_shapes=True).create_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3339,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2b1f55df8d4adfb7449afb0185f1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10, style=ProgressStyle(description_width='iniâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b2210fe4de417cad65a5a966ee40ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43369866060b4134889672fd5447893c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bffb0d2875642fc826d1d69a0fa0cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09ca178ef2b4412ac4f88fa0735275e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a431a49f8844d393f7cfba8a747513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0cbded4ec84a68846e1d3f24073911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab8c51124fc4a87a85c615d17e215fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca8ac3485864a3fb5245343bab62c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65758e94e327415bb0f27ceaac925d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889af9617ca745be86118b8e19de874a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=3339, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    [data['train']['text']],\n",
    "    keras.utils.to_categorical(data['train']['y'],0),\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        TQDMNotebookCallback(\n",
    "            leave_inner=True,\n",
    "        )\n",
    "    ],\n",
    "    validation_data=(\n",
    "        [data['val']['text']],\n",
    "        keras.utils.to_categorical(data['val']['y'],0)\n",
    "    ),\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.epoch,history.history['loss'],history.epoch,history.history['val_loss'])\n",
    "plt.show()\n",
    "#Yellow=Validation set\n",
    "#Blue= Training Set\n",
    "#_=_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "This model is very simple, it consists of only the embedding layer and one dense layer. By looking at the graph above, you can see that the model is not generelizing well on the validation set, when does that usually happen and what can we do to improve it? \n",
    "\n",
    "Please write your answer in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Generalization normally fails in Validation when model get overfit to Training data. To prevent overfitting, we can -\\n1. Add more Data\\n2. Use models with variations and average out their output. i.e. -\\n    a. Either using models of different forms\\n    b. Or through Bagging approach i.e. training it on different subsets of Training data.\\n3. Control the capacity/flexibility of model. It can be done by - \\n    a. Early stopping before it overfits\\n    b. Controlling architecture -- limiting no. of hidden layers\\n    c. Adding Noise\\n    d. Penalizing large weights\\n4. Taking average of predictions generated by varying Weight vectors.\\n'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Generalization normally fails in Validation when model get overfit to Training data. To prevent overfitting, we can -\n",
    "1. Add more Data\n",
    "2. Use models with variations and average out their output. i.e. -\n",
    "    a. Either using models of different forms\n",
    "    b. Or through Bagging approach i.e. training it on different subsets of Training data.\n",
    "3. Control the capacity/flexibility of model. It can be done by - \n",
    "    a. Early stopping before it overfits\n",
    "    b. Controlling architecture -- limiting no. of hidden layers\n",
    "    c. Adding Noise\n",
    "    d. Penalizing large weights\n",
    "4. Taking average of predictions generated by varying Weight vectors.\n",
    "5. Use dropout layers\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use accuracy to evaluate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.predict([data['test']['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on 471 test samples: 0.545648\n"
     ]
    }
   ],
   "source": [
    "predict = np.asarray([np.argmax(i) for i in h])\n",
    "gold = np.asarray(data['test']['y'])\n",
    "resultf1 = accuracy_score(gold, predict)\n",
    "print('Accuracy score on {} test samples: {:.6}'.format(\n",
    "    len(predict), resultf1\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "As you can see, this model is not performing well. What would you change in this model to increase its accuracy?\n",
    "\n",
    "Please write your answer in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThere can be several ways to improve the model -\\n1. We can intoduce more layers like convolution along with pooling etc. And test with different architectures of CNN\\n2. We can use RNN network like LSTM, which stores previous state in memory.\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "There can be several ways to improve the model -\n",
    "1. We can intoduce more layers like convolution along with pooling etc. And test with different architectures of CNN\n",
    "2. We can use RNN network like LSTM, which stores previous state in memory.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(texts):\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        text = text.split()\n",
    "        text_sequence = []\n",
    "        for word in text:\n",
    "            if word in vocabulary:\n",
    "                text_sequence.append(vocabulary[word])\n",
    "        sequences.append(text_sequence)\n",
    "\n",
    "    padded_seq = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return model.predict([padded_seq])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['das ist schlecht',\n",
    "       'ich finde das echt toll',\n",
    "       'das ist gut',\n",
    "       'das ist nicht schlecht',\n",
    "       'das ist nicht gut',\n",
    "       'okay vielen dank',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.40850994  0.21610351  0.28963226] das ist schlecht\n",
      "0 [ 0.4200699   0.13947555  0.36822423] ich finde das echt toll\n",
      "2 [ 0.29508847  0.22653696  0.39167821] das ist gut\n",
      "0 [ 0.45426169  0.22597839  0.2401565 ] das ist nicht schlecht\n",
      "2 [ 0.34084019  0.23641184  0.34220243] das ist nicht gut\n",
      "2 [ 0.15376954  0.19991808  0.56166852] okay vielen dank\n"
     ]
    }
   ],
   "source": [
    "h_ = infer(text)\n",
    "for i,t in enumerate(text):\n",
    "    print('{} {} {}'.format(\n",
    "            np.argmax(h_[i]),\n",
    "            h_[i],\n",
    "            t[:MAX_SEQUENCE_LENGTH],\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Implement a model similar to the one described in [this paper](https://arxiv.org/pdf/1704.06125.pdf), in order to get a much higher accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# # Analysis through CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, GlobalMaxPooling1D, Reshape, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "class BaselineModel2(keras.models.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        input_layer = layers.Input(\n",
    "            shape=(MAX_SEQUENCE_LENGTH,),\n",
    "            name='Input'\n",
    "        )\n",
    "        embedding_layer = layers.Embedding(len(vocabulary) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            name='Embedding',\n",
    "                            trainable=False)(input_layer)\n",
    "\n",
    "        conv1 = Conv1D(200, 2, activation='relu')(embedding_layer)\n",
    "        conv2 = Conv1D(200, 3, activation='relu')(embedding_layer)\n",
    "        conv3 = Conv1D(200, 4, activation='relu')(embedding_layer)\n",
    "        \n",
    "        pool1 = GlobalMaxPooling1D()(conv1)\n",
    "        pool2 = GlobalMaxPooling1D()(conv2)\n",
    "        pool3 = GlobalMaxPooling1D()(conv3)\n",
    "        \n",
    "        conc_layer = keras.layers.concatenate([pool3, pool2, pool1])\n",
    "        drop1 = Dropout(0.5)(conc_layer)\n",
    "        fc_layer1 = layers.Dense(units=30,name='FullyConnected')(drop1)\n",
    "        drop2 = Dropout(0.5)(fc_layer1)\n",
    "        #fc_layer2 = layers.Flatten(name=\"Flatten\")(drop2)\n",
    "        predictions = Dense(3, activation='softmax')(drop2)\n",
    "        super().__init__(inputs=[input_layer], outputs=predictions)\n",
    "        \n",
    "    def compile(self):\n",
    "        return super().compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "            loss='mse'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BaselineModel2()\n",
    "model2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display.display(display.Image(keras.utils.vis_utils.model_to_dot(model2, show_shapes=True).create_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb182710424b426c98b5c71c2fba57de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eb4b46b989498baf8183b4e3c382bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2f9683048a4a4f99fcd726b0deb6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4ec32a0834474ab1404bb2cacc67d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec291571874548998a7742572dd4c482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39bc69a367f41f9b4a2d650322361f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb21112b9cf47d99a4082e903842d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee64a74de9549c89ec44e87fbf7fdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb841cd6d7949c49f9941c6f1f7dfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1e07af35cc43bfae564b981f4e1d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd5cb92a9ac4e74b733e1314d3e28b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=42371), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(\n",
    "    [data['train']['text']],\n",
    "    keras.utils.to_categorical(data['train']['y'],3),\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        TQDMNotebookCallback(\n",
    "            leave_inner=True,\n",
    "        )\n",
    "    ],\n",
    "    validation_data=(\n",
    "        [data['val']['text']],\n",
    "        keras.utils.to_categorical(data['val']['y'],3)\n",
    "    ),\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VPW9//HXJ/u+kUBCEhYNsgYF\nAi5USm2LCq1oBZdWa2971brc29tfe3vb3qX32l97F3t729/VutRau7uAC1YttS1oXUvYZV+FBEIC\nIQkEQrbv748zIZNIyABJzmTm/Xw85pGZM2cmH0bz/s75nHO+x5xziIhIdIjxuwARERk4Cn0RkSii\n0BcRiSIKfRGRKKLQFxGJIgp9EZEootAXEYkiCn0RkSii0BcRiSJxfhfQXW5urhs1apTfZYiIDCor\nV6486JzL6229sAv9UaNGUV5e7ncZIiKDipm9H8p6au+IiEQRhb6ISBRR6IuIRBGFvohIFFHoi4hE\nEYW+iEgUUeiLiESRiAn9umPN/PAP29i0v8HvUkREwlbYnZx1tgzjgWXbaGxuZXxBht/liIiEpZC+\n6ZvZVWa2xcy2m9nXT/H8/zGzjWa2zsz+aGYjg567zcy2BW639WXxwTJT4plZkstL6/aji72LiJxa\nr6FvZrHAg8DVwATgZjOb0G211UCZc24ysAj4r8Brc4BvARcDM4BvmVl235Xf1dzSAirrjrOuor6/\nfoWIyKAWyjf9GcB259xO51wz8CQwP3gF59wy59yxwMN3gKLA/SuBV51ztc65w8CrwFV9U/oHzZkw\njLgY4+X1+/vrV4iIDGqhhH4hsDfocUVgWU++ALxylq89J1kpCV6LZ71aPCIip9KnR++Y2S1AGXD/\nGb7uDjMrN7Pympqac6phXmkBFYfV4hEROZVQQr8SKA56XBRY1oWZfQz4R+Aa59yJM3mtc+5R51yZ\nc64sL6/X6aBPa85EtXhERHoSSuivAMaY2WgzSwBuApYEr2BmU4BH8AK/OuippcAcM8sO7MCdE1jW\nb9TiERHpWa+h75xrBe7FC+tNwNPOuQ1mdp+ZXRNY7X4gDXjGzNaY2ZLAa2uBb+MNHCuA+wLL+lVH\ni2d9pVo8IiLBQjo5yzn3MvByt2X/EnT/Y6d57ePA42db4NmYM3EY33zOeGn9fiYXZQ3krxYRCWsR\nMw1DsKyUBC4ryeVltXhERLqIyNAHmFeaz97a47xXqbl4REQ6RGzoz5mQT2yM1+IRERFPxIZ+dmoC\nl50/RC0eEZEgERv64B3Fs6f2GBv2qcUjIgIRHvpzJqrFIyISLKJDP0ctHhGRLiI69MGbbvn9Q2rx\niIhAFIT+lYEWj+biERGJgtDPSU3g0vPU4hERgSgIffBaPLsPHWOjLpouIlEuKkL/yonD1OIRESFK\nQn9IWiKXnJfDy+ur1OIRkagWFaEPXotn18FGNu0/4ncpIiK+iZrQv3JiPjGGWjwiEtWiJvRz0xK5\nREfxiEiUi5rQB6/Fs1MtHhGJYlEV+ldNUotHRKJbVIW+WjwiEu2iKvShs8WzuUotHhGJPlEX+mrx\niEg0i7rQz01L5OLRQ3hJLR4RiUJRF/oAcycXsLOmkS0H1OIRkegSlaF/VceJWuvU4hGR6BKVoZ+X\nnsiM0Tlq8YhI1InK0Afvouk7ahrZeuCo36WIiAyYqA39KyflY4Yumi4iUSVqQ39oehIzRuXo0E0R\niSpRG/oA8yYXsL36KFt1FI+IRImoDv2rOlo8OopHRKJEVIf+0PQkpqvFIyJRJKTQN7OrzGyLmW03\ns6+f4vlZZrbKzFrNbEG35/7LzDaY2SYz+39mZn1VfF+YV1rAtuqjbFOLR0SiQK+hb2axwIPA1cAE\n4GYzm9BttT3A54Bfd3vtZcBMYDIwCZgOfPicq+5DV+soHhGJIqF8058BbHfO7XTONQNPAvODV3DO\n7XbOrQPau73WAUlAApAIxAMHzrnqPjQ0I4npI9XiEZHoEEroFwJ7gx5XBJb1yjn3NrAM2B+4LXXO\nbTrTIvvb3NJ8th44yvZqtXhEJLL1645cMysBxgNFeAPFFWZ2+SnWu8PMys2svKampj9LOqWrSwsC\nR/FUDfjvFhEZSKGEfiVQHPS4KLAsFNcB7zjnjjrnjgKvAJd2X8k596hzrsw5V5aXlxfiW/edYRlJ\nlI3MVotHRCJeKKG/AhhjZqPNLAG4CVgS4vvvAT5sZnFmFo+3Ezfs2jvgHcWz5cARtXhEJKL1GvrO\nuVbgXmApXmA/7ZzbYGb3mdk1AGY23cwqgIXAI2a2IfDyRcAOYD2wFljrnHuxH/4d50wtHhGJBhZu\nUwuXlZW58vJyX373woffouF4K0u/PMuX3y8icrbMbKVzrqy39aL6jNzu5p5s8Wi6ZRGJTAr9IFdP\nKgB00XQRiVwK/SD5mTqKR0Qim0K/m7mlBWyuOsKOGrV4RCTyKPS7ubo0H9BF00UkMin0uynITGba\nyGxNwCYiEUmhfwodLZ6davGISIRR6J/C3I4Wj77ti0iEUeifQkFmMlNHZPHSep2dKyKRRaHfg7ml\nBWza38Cug41+lyIi0mcU+j2YW6oTtUQk8ij0ezA8K5kpI7J4SYduikgEUeifxrzSAjbub2C3Wjwi\nEiEU+qdxdaDFo2P2RSRSKPRPozArmYuKs9TXF5GIodDvxbzSAjbsa+D9Q2rxiMjgp9DvRcdcPGrx\niEgkUOj3oig7RS0eEYkYCv0QzCst4L1KtXhEZPBT6IdALR4RiRQK/RAUZadwoVo8IhIBFPohmlea\nz3uVDew5dMzvUkREzppCP0QdF01Xi0dEBjOFfoiKc1K4sChTLR4RGdQU+mdgbmkB6yvr1eIRkUFL\noX8GTk63/J6+7YvI4KTQPwPFOSlMVotHRAYxhf4ZmltawLqKevbWqsUjIoOPQv8MzdMVtURkEFPo\nn6HinBRKC9XiEZHBSaF/FuaWFrBWLR4RGYRCCn0zu8rMtpjZdjP7+imen2Vmq8ys1cwWdHtuhJn9\n3sw2mdlGMxvVN6X7p6PF84qO4hGRQabX0DezWOBB4GpgAnCzmU3ottoe4HPAr0/xFj8H7nfOjQdm\nANXnUnA4GDEkhUmFGby0vsrvUkREzkgo3/RnANudczudc83Ak8D84BWcc7udc+uA9uDlgcEhzjn3\namC9o865iOiJzC0tYO3eOioOR8Q/R0SiRCihXwjsDXpcEVgWiguAOjN71sxWm9n9gS2HQe9ki0ff\n9kVkEOnvHblxwOXAV4HpwHl4baAuzOwOMys3s/Kampp+LqlvjBySysThGZqATUQGlVBCvxIoDnpc\nFFgWigpgTaA11Ao8D0ztvpJz7lHnXJlzriwvLy/Et/bf3NIC1uyto7LuuN+liIiEJJTQXwGMMbPR\nZpYA3AQsCfH9VwBZZtaR5FcAG8+8zPDU2eLRt30RGRx6Df3AN/R7gaXAJuBp59wGM7vPzK4BMLPp\nZlYBLAQeMbMNgde24bV2/mhm6wEDftw//5SBNypXLR4RGVziQlnJOfcy8HK3Zf8SdH8FXtvnVK99\nFZh8DjWGtbmlBdy/dAv76o4zPCvZ73JERE5LZ+SeI83FIyKDiUL/HI3KTWVCgVo8IjI4KPT7wLzJ\nBazeU8c+HcUjImFOod8H5qrFIyKDhEK/D4zOTWV8QYZCX0TCnkK/j8wrzWeVWjwiEuYU+n1k7snp\nljUXj4iEL4V+HzkvL41x+elq8YhIWFPo96F5pQWsfP8w++vV4hGR8KTQ70NzJ2u6ZREJbwr9PnS+\nWjwiEuYU+n1sbmkB5e8fZtP+Br9LERH5AIV+H1swrYjctEQWPvw2yzYP+ssBi0iEiazQb2vxuwKG\nZyWz5N6ZjMpN4fM/W8Ejr+3AOed3WSIiQCSF/rFaePBiWPEY+Byyw7OSeebOy5hbWsC/v7KZrzy9\nlqaWNl9rEhGBSAp91w7Zo+Clr8BTt3iDgI+SE2J54OYpfOXjF/Ds6kpufPQdqhuafK1JRCRyQj81\nFz6zCK78LmxdCg9dBrte97UkM+NvPjqGh2+ZxrYDR/jkA2+wrqLO15pEJLpFTugDxMTApffA7X+E\nhDT42TXwh3/zvdd/1aR8Ft91GXExMSx8+G1eWBPqdeVFRPpWZIV+h4IL4c7XYOqt8Mb34fEroXan\nryWNL8hgyb0zubA4iy89uYb7l26mvV07eEVkYEVm6AMkpMI1/wsLfwaHtsPDs2DtU76WNCQtkV9+\n4WJunjGCB5ft4I5frOToiVZfaxKR6BK5od9h4rXwxTchvxSeuwMW3w5N/p04lRAXw3evm8S/XTOR\nZVuq+dSP3mTPoWO+1SMi0SXyQx8gqxhuexFmfxPeWwSPXA4V5b6VY2bcdtkofv75GRxoOMH8B9/g\n7R2HfKtHRKJHdIQ+QGwczP4H+KtXoL3d6/P/+b+h3b/j52eW5PLCPTMZkpbIrT95l1+8875vtYhI\ndIie0O8w4hL44p9h/DXwx/vg5/OhYZ9v5YzKTeXZuy/j8jG5/PPz7/FPz6+npa3dt3pEJLJFX+gD\nJGfBgsdh/o+gcpV3TP+m3/pWTkZSPI/dNp07P3wev3xnD7f+5F1qG5t9q0dEIld0hj6AGUz5DNz5\nOmSNhKc+A7/9MjT7s1M1Nsb4xtXj+Z8bL2TVnjrmP/gGW6qO+FKLiESu6A39Drkl8IVX4bK/hfLH\n4ccfgar3fCvnuilFPHXHJZxoaedTP3qTVzce8K0WEYk8Cn2AuASY82249Tk4fhh+fAW8+4hvE7dN\nGZHNkns/xPlD07jjF+U8uGy7ZuoUkT6h0A92/hVw11tw3mx45Wvw6xuh8aAvpeRnJvH0nZfyycnD\nuX/pFr705BrN1Cki50yh311qLnz6Kbj6v2Dncm8n744/+VJKUnwsP7zpIv7+yrG8uG4fNzzyNlX1\nmqlTRM6eQv9UzODiO+H2P0FyNvziOvj9P0HrwB9RY2bc85ESHr21jB3VR/nkA2+wes/hAa9DRCJD\nSKFvZleZ2RYz225mXz/F87PMbJWZtZrZglM8n2FmFWb2QF8UPWDyJ8Hty6Ds8/DW/8JPPg6HdvhS\nyscnDOPZu2eSFB/DjY++w3OrK3ypQ0QGt15D38xigQeBq4EJwM1mNqHbanuAzwG/7uFtvg34O7n9\n2UpIgU/8D9z4S6h7Hx6+HFb/ypedvGPz03nhng8xdUQWX35qLf/+8ibaNFOniJyBUL7pzwC2O+d2\nOueagSeB+cErOOd2O+fWAR84ldTMpgHDgN/3Qb3+Gf9Jb+K2wqnwwt2w+AtwfOAviJKTmsAvvnAx\nt1wygkde38ntPy/nSJP/1wYWkcEhlNAvBPYGPa4ILOuVmcUA/w189cxLC0OZhfDZF+CKf4YNz3vf\n+ve8O+BlxMfG8H+vLeXb107i9a01XPejt9h9sHHA6xCRwae/d+TeDbzsnDttA9rM7jCzcjMrr6mp\n6eeSzlFMLMz6Knzh994O359eDcv/05eJ2269ZCQ//8IMDh49wfwH3+TN7f4cXioig0cooV8JFAc9\nLgosC8WlwL1mthv4HvBZM/uP7is55x51zpU558ry8vJCfGufFZXBF9+ASdfD8u/CE5+Aur29v66P\nXXZ+Lkvu+RDDMhL57ON/4Yk3d+lELhHpUSihvwIYY2ajzSwBuAlYEsqbO+c+45wb4Zwbhdfi+blz\n7gNH/wxaSRlw/Y/hukehah08PNNr+wywEUNSWHzXZXxkbB7/+uJGvvnceppbNVOniHxQr6HvnGsF\n7gWWApuAp51zG8zsPjO7BsDMpptZBbAQeMTMNvRn0WHnwhu96ZqHlMAzt8GSv4GW4wNaQnpSPI/e\nWsbds8/nN3/Zyy2PvcuhoycGtAYRCX8Wbq2AsrIyV17u31WtzklbCyz7LrzxP1AwGW78lXfVrgH2\nwppKvrZoHdkpCdxzRQkLpxWRFB874HWIyMAxs5XOubLe1tMZuX0pNh4+9i24+Umo3QWPzobdbw54\nGfMvKuSZL15KfmYS//z8e3zoP5fx0PIdOrRTRPRNv9/UbIUnPw2Hd8FV/wHT/9o72mcAOed4e+ch\nHlq+gz9vO0h6UhyfvXQkfzVzNLlpiQNai4j0r1C/6Sv0+1NTPSy+HbYthamfhbnfgzh/wnZdRR0P\nLd/B7zZUkRgXw41lxdw+6zyKslN8qUdE+pZCP1y0t3l9/j9/D4pmwI2/gPR838rZXn2UR17bwXOr\nvaNu519UyF2zz6NkaLpvNYnIuVPoh5sNz8Pzd0FSpjePT1Gv/2361b664/z4zzv5zV/2cKK1nTkT\nhnH37BIuLM7ytS4ROTsK/XBU9Z7X5z+y35vEbcotfldEbWMzT7y5iyfe2k1DUyszS4Zw9+wSLjt/\nCDbA+yBE5Owp9MPVsVp45nOw6zWYcSdc+R3vqB+fHT3Ryq/ffZ/H/ryL6iMnuLAok7tmlzBnwjBi\nYhT+IuFOoR/O2lrhD9+Ctx+AUZfDwie8K3aFgaaWNhavquCR13ayp/YYJUPT+OKHz2f+RcOJj9UR\nviLhSqE/GKx9Epb8LaQNg5t+5Z3QFSZa29p5af1+Hlq+g81VRyjMSuaOWedxQ1kxyQk60Usk3Cj0\nB4vKVfDULV7bZ/4DUPqBC4/5yjnHsi3V/GjZDsrfP8yQ1AQ+/6HR3HLJSDKT/W9LiYhHoT+YHK2G\npz8Le96GmV+Cj37Lm8I5zPxlVy0/Wr6d5VtqSEuM45ZLRvL5D41iaHqS36WJRD2F/mDT2gy/+wco\nfxxKPgbXP+ZdlD0MbdhXz0PLd/Dy+v3ExcZwQ1kRd846n+Icnegl4heF/mBV/lN4+e+9idpu+g0M\nHed3RT3adbCRR1/fweKVlbQ5xycnF3DX7BLG5utEL5GBptAfzPa8A0/dCi3H4FOPwrh5fld0WlX1\nTfzkjZ386t09HGtu42Pjh3LX7BKmjQzPLRWRSKTQH+zqK70dvPtWwexvwKyvQUx4HzJ5uLGZn729\nmyfe2k3dsRYuHp3DPR8p4fIxuTrRS6SfKfQjQUsT/PbvYO1vYNwn4LqHITH8WyeNJ1r5zV/28Nif\nd1HV0MS4/HRuKCtm/kXDGaLZPUX6hUI/UjgH7z4MS/8RcsfATb+GIef7XVVITrS28fzqSn717h7W\nVdQTF2NcMW4oC6YV8ZFxQ3Wyl0gfUuhHmp3LvekbXDtc/ziM+ZjfFZ2RLVVHWLyqgmdXVXLw6AmG\npCYw/6JCFkwrYsLwDL/LExn0FPqR6PBuePIzUL3RO5Z/5pcG/MIs56q1rZ3Xt9WwaGUFr248QEub\nY0JBBgumFXHtlEJyUhP8LlFkUFLoR6rmRnj+btj4PExaANf8LyQMzuPjDzc2s2TtPhatrGB9ZT3x\nsR3tn2Jmj81T+0fkDCj0I5lz8Mb34Y/fhvxJXp8/a4TfVZ2TzVUNLF5ZwXOrKzl4tJkhqQlcO8Vr\n/4wvUPtHpDcK/WiwdSks/mtvauaFP4PRl/td0TlraWvn9a1e++cPm7z2z8ThXvtn/kVq/4j0RKEf\nLQ5u8y7McmiHdwH2GbcPuj5/T3pq/yycVsyH1f4R6UKhH02a6uHZO2HrK97VuOZ937cLsPeXTfu9\n9s/za7z2T25aAtdeVMj1av+IAAr96NPeDsu/C6/fD4Vl3nV4Mwr8rqrPtbS189oWr/3zx81e+2dS\nYQYLphZxjdo/EsUU+tFq4wvw3F2QmObN1Fk0HeKT/a6qX9Q2NrNkTSWLVlXwXmUD8bHGR8cNY8G0\nIrV/JOoo9KPZgQ1en//wbu9xQjqkDfVuqXmBn0ODlg2FtDzv5yA9/LOn9s+CsiLG5av9I5FPoR/t\njh+GzS/BkSporIGjB+BoDTRWexdtaao79esS0jsHgJM/hwXdDxo4ElIH9t8UgtO1f+ZMzKcgM0mT\nv0lEUujL6bU2dw4GjTXeQNBY3XVg6Fh2/PCp3yMhLWjLIS8wOJxiayK9AOIH/upatY3NvLCmkkUr\nK9iwrwGA3LREJhdlUlqYyYXFmZQWZpGXHlk7vSU6KfSl77Q2w7GDXQeCo9XdBovA7XjtKd7AvIvC\n5F4AQ8Z4E8fljvEepw0bkENMN1c18O7OWtZV1LO+so7t1UdpD/yvX5CZRGlhJpOLMplclEVpYSbZ\n2iEsg0yooR83EMXIIBeXABnDvVtv2lqg8WDnVsPRA1C/1zuf4NA2eP8t7+IwHRIzYEhJ14FgyBjI\nOa9Ptw7G5Wd06e03nmhl4/4G1u6tY31lPesr6vn9xgMnny/OSWZyYRalRd5gMKkwk4wkXQheBr+Q\nvumb2VXAD4FY4DHn3H90e34W8ANgMnCTc25RYPlFwENABtAGfMc599Tpfpe+6Uc456BhHxzc2jkQ\nHNwKB7dDQ0XnehbjTS1xqq2D1Lx+2TpoaGrhvcp6b2ugop51lXXsrT1+8vnzclMpDbSGJhdlMXF4\nBqmJ+t4k4aHP2jtmFgtsBT4OVAArgJudcxuD1hmFF+xfBZYEhf4FgHPObTOz4cBKYLxzroe9iAr9\nqNbcCIe2e4PBwcBgcGibNyC0doYviZlBg8CYwKBwgbd1ENe3bZnDjc3elkBl/cmtgv31TQDEGJQM\nTaO0MMvbT1CUyYSCDJLiY/u0BpFQ9GV7Zwaw3Tm3M/DGTwLzgZOh75zbHXiuPfiFzrmtQff3mVk1\nkAf0GPoSxRJSoeBC7xasvR0aKj+4dbDzNe+qYh0sFrJHBrYOSryfHVsHKUPOausgOzWBWRfkMeuC\nvJPLqo808V5lPWv3eoPBa1urWbzK20qJizEuGJZ+chCYXJjF2Px0EuJ0zoCEh1BCvxDYG/S4Arj4\nTH+Rmc0AEoAdZ/paiXIxMd6O4KxiKPlo1+dOHDnF1sF276IzrU2d6yVlQd5YyBsHQ8cH7o+H9Pwz\nHgyGpidxxbgkrhg3DADnHFUNTSfbQmsr6vjdhiqeXOH92STExjC+IP3kIPDhsXkMyxj4o5lEYIB2\n5JpZAfAL4DbnXPspnr8DuANgxIjBPUWwDLDEdBg+xbsFa2/v3IF8cGvnbdOLsOpnneslZXrhnzc2\nMBgEBoUzOKrIzCjITKYgM5krJ+YD3kBQcfg46yrqWVdRx7qKel5YvY9fvrOHGIPLx+Rx/bQi5kwY\npnaQDKhQevqXAv/qnLsy8PgbAM65fz/Fuk8Av+3o6QeWZQDLge8GL++JevrSr5zzDjWt2QzVm6Fm\nU+fP4PMRkrICA8A4b1AYOs57fA6HmLa3O7bXHGXJmn08u6qCffVNpCfF8ckLh3P91CKmjsjSiWNy\n1vpyR24c3o7cjwKVeDtyP+2c23CKdZ8gKPTNLAF4BXjROfeDUApX6IsvOgaD6k3egBA8KHQfDDq2\nCIIHhbShZzQYtLc73t55iMUrK3j5vf00tbRzXm4q108r4rophQzPisz5kqT/9OnJWWY2F++QzFjg\ncefcd8zsPqDcObfEzKYDzwHZQBNQ5ZybaGa3AD8FggeIzznn1vT0uxT6Elac8046OzkQbOr8GTyV\nRXJ20EAQ1CYK4fDSI00tvLK+ikWrKvjLrlrM4EMluVw/tYgrJ+aTnKD2j/ROZ+SK9KeTg0FQe6hm\nSw+DwfjOLYK8sd5Jbsk5kJwFMV0Dfc+hYyxeVcHiVRVUHD5OWmIc80oLWFBWRNnIbLV/pEcKfRE/\nOOedhVwdGASCB4Wm+m4rm7cjOTkbUnK8gSAlB5KzaU/KZvfxRN7a51i+p4WqlhRSs/KYfdE4Pjl9\nDEU54TfZnfhLoS8STjoGg5rN3hbCsVpvX8Hx2sD9wOOO5ScaenyrZhfLsdgMYlJySM0eSmxKDqRk\ndxk0Ou/ndA4qEXY1NelKc++IhBMz75yA9PzQ1m9rgeN1XQeFY7XU1Vazffce9u2vJL6+jiFH6ilK\nOkBuTCPxzXVY24me3zM+NTAQZHknq2WP8k5iG1ICOed7j/v4jGYJPwp9kXAUG+9dwyAtr8viLKAM\n7zyAFbsPs3hlBS+t38/RE60UZydxw4V5fGpcMoWJx7ttPdTCscOdWxeNNbBxSddZUS0GskZ2DgRD\nzg/cSiCjyDtJTgY9tXdEBrnjzW0s3VDFopUVvLnjIM7BjNE5LJhWxNzSAtJONyncsVqo3emdxXxo\nOxza0fmzpbFzvdhEb26jjkHg5KBQ0m8T4PWr9rauW1KtTd7+leBbzOA6ako9fZEotK/uOM+t9i4c\ns+tgI8nxsVw9KZ8F04q45LwhxMSEGM7OeVddq93RbUDY4Q0S7S2d6yZmeANATvcB4XwvPPtb64ku\nLTDv56HO/SPHAo+77D+pA3rJvsSMwACQ1TkQJAfdP93yhNQBHwgV+iJRzDnHqj11LFpZwW/X7uPI\niVYKs5L51NRCrp9axKjcczj6p63Vm+KiY6sgeGCo20uXME3N67pV0DEw5IyG+G4noDnnzbTaJaAP\nBwV491APtKqaj/Zca3xK507t4COkUoZ03dkdl+jtPG+q927H6zrvN9V9cHnzkdN/RjFx3bYcTjdw\nZHUuT86B1CFn9Z9FoS8iADS1tPH7jQdYtLKCN7bV0O5g2shsykZlM3ZYOmPz0ykZmkZiXB+0M1qa\n4PDuoK2D7Z3to6MHglY0yCz2zlk40dAZ5m3NPb93UmbPod1TqPfXZTrbWgODRF1og0Tw8uN10NMO\n9+FT4Y5lZ1WSQl9EPqCqvonnVlfy0vp9bKk6Qkub9/cfG2OMzk09OQiMzU9nXH46xdkpobeEetPU\nENgq2NG5lXBkv9dG6e2beHI2xEbQcSctTaceIBJSYdzcs3pLhb6InFZLWzu7DjaypeoIW6qOsLnq\nCFsPHGFPbeflLJPjY7lgWBpj89O5YFg64/IzGJufrovJhyGFvoiclcYTrWw94A0EWzp+Vh3hUGNn\n62VIagIXDOvcIrggP52xw9J1+Ugf6eQsETkrqYlxTBmRzZQR2V2WHzx64uQWwZaqBrYcOMpTK/Zy\nvKXt5DrFOcmMHZbB2Pw0xuZnMC4/ndG5qcTH6hj/cKHQF5GQ5KYlkluSyMyS3JPL2tsdew8f62wR\nBbYMlm2ppq3d6yLExxrn56Wd3FfQsd+gMCtZE8j5QKEvImctJsYYOSSVkUNSmTOxc4qJE61t7Khu\nZMuBBrZUHWVLVQMrdtXywpri1mtkAAAGrElEQVR9J9dJS4zjvLxUUhJiSYyLJTEuhsT4wM+4GBLj\nYknouB8f07lOYL2E2I7lnc8lxceQEBvbZXlCXAyxfbUzOgIo9EWkzyXGxTJheAYThmd0WV5/vIVt\nBzpaREfYfaiREy3t1B1r5kRru3draeNEazvNgcfNbR+4wuoZi4+1roNIx0ARGByGZSRx7UWFzB6b\nR1yEt6IU+iIyYDKT4ykblUPZqJyQX9Pe7mhua+dESzsnWts6B4eO+4HlzSeXB55raQ8aPNo+sDz4\nNe/sPMRv1+0nLz2RT00pZGFZESVD0/vxk/CPQl9EwlpMjJEUExu4gHx8v/yOlrZ2lm+p4enyvTz2\nxi4eeX0nU0dksbCsmE9MLiA9qX9+rx90yKaISJCaIyd4fnUlT5fvZVv1UZLiY5hbWsANZcVcPDon\nbHc+6zh9EZFz4Jxjzd46nllZwYtrvPmLRuSksHBaEddPKwq7i9cr9EVE+sjx5jZ+t2E/z5RX8NaO\nQycvXn9DWTEfnzAs0Hryl0JfRKQf7K09xjMrK1i8soLKuuNkJscz/6Lh3FBWzMThGb61fxT6IiL9\nqL3d8daOQzxdvpffbaiiubWd8QUZLJxWxLVTCslJHdhLTyr0RUQGSP2xFpas28cz5XtZV1FPfKzx\n8QnDWDitmMvH5A7Isf8KfRERH2yuauCZ8gqeW11JbWMzwzISuX5qEQvLihl9Lhev6YVCX0TER82t\n7fxpczXPlO9l2ZZq2h1MH5XNwrJi5pUW9PmMpAp9EZEwUd3QxLOBY/931jSSkhDLvNICbpheTNnI\n7D7Z+avQFxEJM961iw/zTHkFL67dR2NzG6NzU1kwrYjrpxaRn3n2l3dU6IuIhLFjza28vL6KZ8r3\n8u6uWmIM5pYW8MCnp57V++kiKiIiYSwlIY4F04pYMK2I3QcbWbSyAkf/fwlX6IuI+GxUbipfvXLs\ngPyuyJ44WkREuggp9M3sKjPbYmbbzezrp3h+lpmtMrNWM1vQ7bnbzGxb4HZbXxUuIiJnrtfQN7NY\n4EHgamACcLOZTei22h7gc8Cvu702B/gWcDEwA/iWmWUjIiK+COWb/gxgu3Nup3OuGXgSmB+8gnNu\nt3NuHdD9umZXAq8652qdc4eBV4Gr+qBuERE5C6GEfiGwN+hxRWBZKM7ltSIi0sfCYkeumd1hZuVm\nVl5TU+N3OSIiESuU0K8EioMeFwWWhSKk1zrnHnXOlTnnyvLy8kJ8axEROVOhhP4KYIyZjTazBOAm\nYEmI778UmGNm2YEduHMCy0RExAchTcNgZnOBHwCxwOPOue+Y2X1AuXNuiZlNB54DsoEmoMo5NzHw\n2s8D3wy81Xeccz/t5XfVAO+f7T8IyAUOnsPrI4k+i670eXSlz6NTJHwWI51zvbZKwm7unXNlZuWh\nzD8RDfRZdKXPoyt9Hp2i6bMIix25IiIyMBT6IiJRJBJD/1G/Cwgj+iy60ufRlT6PTlHzWURcT19E\nRHoWid/0RUSkBxET+r3NBBpNzKzYzJaZ2UYz22BmX/K7Jr+ZWayZrTaz3/pdi9/MLMvMFpnZZjPb\nZGaX+l2Tn8zsy4G/k/fM7DdmdvbXLBwEIiL0Q5wJNJq0Al9xzk0ALgHuifLPA+BLwCa/iwgTPwR+\n55wbB1xIFH8uZlYI/C1Q5pybhHcu0k3+VtW/IiL0CWEm0GjinNvvnFsVuH8E7486aie6M7MiYB7w\nmN+1+M3MMoFZwE8AnHPNzrk6f6vyXRyQbGZxQAqwz+d6+lWkhL5m8+yBmY0CpgDv+luJr34AfI0P\nTv0djUYDNcBPA+2ux8ws1e+i/OKcqwS+h3dNkP1AvXPu9/5W1b8iJfTlFMwsDVgM/J1zrsHvevxg\nZp8Aqp1zK/2uJUzEAVOBh5xzU4BGIGr3gQXmBJuPNxgOB1LN7BZ/q+pfkRL65zITaEQys3i8wP+V\nc+5Zv+vx0UzgGjPbjdf2u8LMfulvSb6qACqccx1bfovwBoFo9TFgl3OuxjnXAjwLXOZzTf0qUkL/\nXGYCjThmZng9203Oue/7XY+fnHPfcM4VOedG4f1/8SfnXER/kzsd51wVsNfMxgYWfRTY6GNJftsD\nXGJmKYG/m48S4Tu24/wuoC8451rN7F68aZs7ZgLd4HNZfpoJ3AqsN7M1gWXfdM697GNNEj7+BvhV\n4AvSTuCvfK7HN865d81sEbAK76i31UT42bk6I1dEJIpESntHRERCoNAXEYkiCn0RkSii0BcRiSIK\nfRGRKKLQFxGJIgp9EZEootAXEYki/x8oWxJAO6vVzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faefbd27ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.epoch,history.history['loss'],history.epoch,history.history['val_loss'])\n",
    "plt.show()\n",
    "_=_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on 471 test samples: 0.728238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "h = model2.predict([data['test']['text']])\n",
    "predict = np.asarray([np.argmax(i) for i in h])\n",
    "gold = np.asarray(data['test']['y'])\n",
    "resultf1 = accuracy_score(gold, predict)\n",
    "print('Accuracy score on {} test samples: {:.6}'.format(\n",
    "    len(predict), resultf1\n",
    "))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# # Analysing with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, GlobalMaxPooling1D, Bidirectional, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "class BaselineModel3(keras.models.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        input_layer = layers.Input(\n",
    "            shape=(MAX_SEQUENCE_LENGTH,),\n",
    "            name='Input'\n",
    "        )\n",
    "        print(input_layer.shape)\n",
    "        embedding_layer = layers.Embedding(len(vocabulary) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            name='Embedding',\n",
    "                            trainable=False)(input_layer)\n",
    "        print(embedding_layer.shape)\n",
    "        drop1 = Dropout(0.5)(embedding_layer)\n",
    "        bi_lay = Bidirectional(LSTM(200, return_sequences=False))(drop1)\n",
    "        drop2 = Dropout(0.5)(bi_lay)\n",
    "        print(drop2.shape)\n",
    "        f_con = Dense(30, activation=\"sigmoid\")(drop2)\n",
    "        drop3 = Dropout(0.5)(f_con)\n",
    "        print(drop3.shape)\n",
    "        predictions = Dense(3, activation='softmax')(drop3)\n",
    "        \n",
    "        super().__init__(inputs=[input_layer], outputs=predictions)\n",
    "        \n",
    "    def compile(self):\n",
    "        return super().compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "            loss='mse'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 200)\n",
      "(?, 200, 100)\n",
      "(?, ?, 400)\n",
      "(?, 200, 30)\n"
     ]
    }
   ],
   "source": [
    "model3 = BaselineModel3()\n",
    "model3.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42371, 200)\n"
     ]
    }
   ],
   "source": [
    "print(data['train']['text'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display.display(display.Image(keras.utils.vis_utils.model_to_dot(model3, show_shapes=True).create_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_11 to have 3 dimensions, but got array with shape (42371, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-fe159a32beb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     ),\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1572\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1574\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1575\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1409\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1412\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1413\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_11 to have 3 dimensions, but got array with shape (42371, 3)"
     ]
    }
   ],
   "source": [
    "history = model3.fit([data['train']['text'].reshape()],keras.utils.to_categorical(data['train']['y'],3),\n",
    "                     epochs=10,verbose=0,callbacks=[TQDMNotebookCallback(leave_inner=True,)\n",
    "    ],\n",
    "    validation_data=(\n",
    "        [data['val']['text']],\n",
    "        keras.utils.to_categorical(data['val']['y'],3)\n",
    "    ),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.epoch,history.history['loss'],history.epoch,history.history['val_loss'])\n",
    "plt.show()\n",
    "_=_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "h = model2.predict([data['test']['text']])\n",
    "predict = np.asarray([np.argmax(i) for i in h])\n",
    "gold = np.asarray(data['test']['y'])\n",
    "resultf1 = accuracy_score(gold, predict)\n",
    "print('Accuracy score on {} test samples: {:.6}'.format(\n",
    "    len(predict), resultf1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9595083  0.26233734 0.30014796]\n",
      "[[0.95685904]\n",
      " [0.90399242]\n",
      " [0.78772734]\n",
      " [0.52574663]]\n",
      "[[0.5834513  0.14647375 0.14317278]\n",
      " [0.05805849 0.22996969 0.32466572]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "a= np.random.rand(8,6)\n",
    "b=np.random.rand(3,)\n",
    "c=np.random.rand(4,1)\n",
    "#print((a+b).shape) \n",
    "print(b)\n",
    "print(c)\n",
    "print(a[:2,1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "663px",
    "left": "1713.33px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
